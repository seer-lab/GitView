#!/bin/bash

LOCATION=

# The directory where the log files will go
LOGDIR="$LOCATION"testlog/
# The file that the log will be saved to. Format: testmmddyyyy_HHMM
LOGFILE=test$(date +"%m%d%Y_%H%M")

# Full path of the file
FULLPATH=$LOGDIR$LOGFILE

# The username used to login with for github api
#USERNAME=dataBaseError

# The password for that user
#read -s -p "Password: " password
# Extra echo so everything following will begin on a new line
#echo

# The repo to be scraped and then parsed.
REPO_OWNER=$1
REPO_NAME=$2

# Make the directory if it doesnt already exist
#mkdir -p $LOGDIR

#echo $REPO_OWNER $REPO_NAME

touch $FULLPATH

# Run the script in a virtual screen to allow for access to the server still
ruby1.9.1 "$LOCATION"src/github_api.rb $REPO_OWNER $REPO_NAME 2>&1 | tee $FULLPATH
#ruby1.9.1 /home/joseph/source_code/GitHubMining/src/test.rb $REPO_OWNER $REPO_NAME 2>&1 $FULLPATH

# Store the error code of the scraping ruby script
RESULT=$?

# Show the location of the log file for the scraping
echo log file: $FULLPATH


#ls . 2>&1 | tee $FULLPATH

# If the github scrap was successful move on to parsing the file
if [[ $RESULT == 0 ]]; then
	ruby1.9.1 "$LOCATION"src/file_parser.rb $REPO_OWNER $REPO_NAME true $FULLPATH

	# If the test parse does not yeild an error then run the actual thing (not as a test) to store in the db
	if [[ $? == 0 ]]; then		
		ruby1.9.1 "$LOCATION"src/file_parser.rb $REPO_OWNER $REPO_NAME false $FULLPATH
	fi
fi